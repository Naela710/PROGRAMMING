{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5b87124-511a-4447-b87d-7d6fb53735e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\anaconda3\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d55f569a-d1ee-4ee7-9701-139e7f5a31fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4e4ec41f-f9ef-4153-b2ac-8689e7a94e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://books.toscrape.com/catalogue/page-{}.html\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "738dec5a-8b4f-4aa3-b6ae-23ca38f215db",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(base_url.format(1))\n",
    "html_source = response.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "143be7a5-f394-4c0a-b22c-6c68be04fe9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyser le code HTML\n",
    "soup = BeautifulSoup(html_source, 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b45aec1a-60b1-4538-a8dc-e84eb5f7cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "57ed5f5e-2333-4c9c-bf74-6f703e923813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour récupérer les détails d'un livre donné\n",
    "def get_book_details(book_url):\n",
    "    response = requests.get(book_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "    # Extraire le genre\n",
    "    breadcrumb = soup.find('ul', class_='breadcrumb')\n",
    "    if breadcrumb:\n",
    "        breadcrumb_items = breadcrumb.find_all('li')\n",
    "        if len(breadcrumb_items) > 2:\n",
    "            genre = breadcrumb_items[2].text.strip()\n",
    "        else:\n",
    "            genre = \"Unknown genre\"\n",
    "    else:\n",
    "        genre = \"Unknown genre\"\n",
    "\n",
    "    # Extraire la description\n",
    "    description = soup.find('meta', {'name': 'description'})\n",
    "    if description:\n",
    "        description = description['content'].strip()\n",
    "    else:\n",
    "        description = \"No description available\"\n",
    "    \n",
    "    return genre, description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "92173f80-5d67-4b6b-bb51-6401928896be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction pour récupérer les URL des livres sur une page donnée\n",
    "def get_books_from_page(page_url):\n",
    "    response = requests.get(page_url)\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    \n",
    "    # Sélectionner tous les livres sur la page\n",
    "    books = soup.select('article.product_pod h3 a')\n",
    "    \n",
    "    # Récupérer les liens vers chaque livre\n",
    "    book_urls = ['https://books.toscrape.com/catalogue/' + book['href'].replace('../../../', '') for book in books]\n",
    "    \n",
    "    return book_urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a735102-b161-4590-b99e-33737b0df240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Page 1 traitée.\n",
      "Page 2 traitée.\n",
      "Page 3 traitée.\n",
      "Page 4 traitée.\n",
      "Page 5 traitée.\n",
      "Page 6 traitée.\n",
      "Page 7 traitée.\n",
      "Page 8 traitée.\n",
      "Page 9 traitée.\n",
      "Page 10 traitée.\n",
      "Page 11 traitée.\n",
      "Page 12 traitée.\n",
      "Page 13 traitée.\n",
      "Page 14 traitée.\n",
      "Page 15 traitée.\n",
      "Page 16 traitée.\n",
      "Page 17 traitée.\n",
      "Page 18 traitée.\n",
      "Page 19 traitée.\n",
      "Page 20 traitée.\n",
      "Page 21 traitée.\n",
      "Page 22 traitée.\n",
      "Page 23 traitée.\n",
      "Page 24 traitée.\n",
      "Page 25 traitée.\n",
      "Page 26 traitée.\n",
      "Page 27 traitée.\n",
      "Page 28 traitée.\n",
      "Page 29 traitée.\n",
      "Page 30 traitée.\n",
      "Page 31 traitée.\n",
      "Page 32 traitée.\n",
      "Page 33 traitée.\n",
      "Page 34 traitée.\n",
      "Page 35 traitée.\n",
      "Page 36 traitée.\n",
      "Page 37 traitée.\n",
      "Page 38 traitée.\n",
      "Page 39 traitée.\n",
      "Page 40 traitée.\n",
      "Page 41 traitée.\n",
      "Page 42 traitée.\n",
      "Page 43 traitée.\n",
      "Page 44 traitée.\n",
      "Page 45 traitée.\n",
      "Page 46 traitée.\n",
      "Page 47 traitée.\n",
      "Page 48 traitée.\n",
      "Page 49 traitée.\n",
      "Page 50 traitée.\n"
     ]
    }
   ],
   "source": [
    "# Lancer le scraping pour toutes les pages\n",
    "all_books = []\n",
    "for page in range(1, 51):  # Le site a 50 pages de livres\n",
    "    page_url = base_url.format(page)\n",
    "    book_urls = get_books_from_page(page_url)\n",
    "    \n",
    "    for book_url in book_urls:\n",
    "        # Récupérer le titre, la note, le prix, et la disponibilité\n",
    "        response = requests.get(book_url)\n",
    "        soup = BeautifulSoup(response.text, 'html.parser')\n",
    "        \n",
    "        # Titre du livre\n",
    "        title = soup.find('h1').text\n",
    "        \n",
    "        # Prix du livre\n",
    "        price = soup.find('p', class_='price_color').text\n",
    "        \n",
    "        # Disponibilité\n",
    "        availability = soup.find('p', class_='instock availability').text.strip()\n",
    "\n",
    "        # Note en étoiles (extraite à partir des classes CSS)\n",
    "        star_rating = soup.find('p', class_='star-rating')['class'][1]\n",
    "        \n",
    "        # Récupérer le genre et la description\n",
    "        genre, description = get_book_details(book_url)\n",
    "        \n",
    "        # Ajouter les informations à la liste\n",
    "        all_books.append({\n",
    "            'title': title,\n",
    "            'price': price,\n",
    "            'availability': availability,\n",
    "            'star_rating': star_rating,\n",
    "            'genre': genre,\n",
    "            'description': description,\n",
    "            'url': book_url\n",
    "        })\n",
    "        \n",
    "    print(f\"Page {page} traitée.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8dd1e700-5a78-45cf-b8a2-51b12f6425eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping terminé et fichier CSV généré.\n"
     ]
    }
   ],
   "source": [
    "# Exporter les données dans un fichier CSV\n",
    "keys = all_books[0].keys()\n",
    "with open('books_data.csv', 'w', newline='', encoding='utf-8') as output_file:\n",
    "    dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
    "    dict_writer.writeheader()\n",
    "    dict_writer.writerows(all_books)\n",
    "\n",
    "print(\"Scraping terminé et fichier CSV généré.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32c9a28-c4c1-4285-922d-bbe7681efeec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
